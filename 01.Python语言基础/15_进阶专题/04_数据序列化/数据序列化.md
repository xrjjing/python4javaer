# 数据序列化

数据序列化是将数据结构或对象转换为可存储或传输格式的过程。Python提供了多种序列化方案，适用于不同场景。

## 目录

1. [JSON - 通用数据交换](#1-json)
2. [CSV - 表格数据](#2-csv)
3. [pickle - Python对象](#3-pickle)
4. [配置文件格式](#4-配置文件)
5. [格式选择指南](#5-格式选择)

---

## 1. JSON - 通用数据交换

### 基本用法

```python
import json

# Python → JSON字符串
data = {"name": "张三", "age": 25, "skills": ["Python", "Java"]}
json_str = json.dumps(data, ensure_ascii=False, indent=2)

# JSON字符串 → Python
parsed = json.loads(json_str)

# 文件操作
with open("data.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

with open("data.json", "r", encoding="utf-8") as f:
    loaded = json.load(f)
```

### 数据类型映射

| Python | JSON | 说明 |
|--------|------|------|
| dict | object | 字典 → 对象 |
| list, tuple | array | 序列 → 数组 |
| str | string | 字符串 |
| int, float | number | 数字 |
| True/False | true/false | 布尔值 |
| None | null | 空值 |

### 自定义编码器

```python
from datetime import datetime
from decimal import Decimal

class CustomEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        if isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)

data = {"time": datetime.now()}
json.dumps(data, cls=CustomEncoder)
```

### 常用参数

```python
json.dumps(data,
    ensure_ascii=False,  # 允许中文
    indent=2,            # 缩进美化
    sort_keys=True,      # 键排序
    separators=(',', ':')  # 紧凑格式
)
```

---

## 2. CSV - 表格数据

### DictWriter/DictReader（推荐）

```python
import csv

# 写入
employees = [
    {"name": "张三", "dept": "技术部", "salary": 12000},
    {"name": "李四", "dept": "销售部", "salary": 15000},
]

with open("data.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["name", "dept", "salary"])
    writer.writeheader()
    writer.writerows(employees)

# 读取
with open("data.csv", "r", encoding="utf-8") as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row["name"], row["salary"])
```

### writer/reader（列表方式）

```python
# 写入
with open("data.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["姓名", "部门", "薪资"])
    writer.writerow(["张三", "技术部", 12000])

# 读取
with open("data.csv", "r", encoding="utf-8") as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)  # ['张三', '技术部', '12000']
```

### 处理特殊字符

```python
# 自定义分隔符和引号
with open("data.csv", "w", newline="") as f:
    writer = csv.writer(f,
        delimiter='\t',      # 使用制表符
        quotechar='"',       # 引号字符
        quoting=csv.QUOTE_MINIMAL  # 引号策略
    )
```

---

## 3. pickle - Python对象

### 基本用法

```python
import pickle

# 序列化对象
data = {"users": [1, 2, 3], "config": {"debug": True}}

# 保存到文件
with open("data.pkl", "wb") as f:
    pickle.dump(data, f)

# 从文件加载
with open("data.pkl", "rb") as f:
    loaded = pickle.load(f)

# 序列化为字节串
bytes_data = pickle.dumps(data)
loaded = pickle.loads(bytes_data)
```

### 可序列化的类型

- ✅ 内置类型（list、dict、set等）
- ✅ 自定义类的实例
- ✅ 函数引用（模块级函数）
- ✅ 类定义
- ❌ 文件句柄、网络连接
- ❌ Lambda函数、嵌套函数

### 安全警告

```python
# ⚠️ 危险：不要加载不可信的pickle数据
# pickle可以执行任意代码！

# 安全做法：
# 1. 仅在可信环境使用
# 2. 验证数据来源
# 3. 考虑使用JSON替代
```

---

## 4. 配置文件

### 4.1 INI格式（ConfigParser）

```python
from configparser import ConfigParser

config = ConfigParser()

# 创建配置
config['database'] = {
    'host': 'localhost',
    'port': '3306',
    'username': 'root'
}

# 写入文件
with open('config.ini', 'w') as f:
    config.write(f)

# 读取文件
config.read('config.ini')
host = config['database']['host']
port = config.getint('database', 'port')  # 自动转换类型
```

### 4.2 环境变量

```python
import os

# 读取环境变量
db_host = os.getenv('DB_HOST', 'localhost')  # 带默认值
api_key = os.environ['API_KEY']  # 必须存在

# 设置环境变量
os.environ['MY_VAR'] = 'value'
```

### 4.3 .env文件（推荐）

使用第三方库 `python-dotenv`：

```python
from dotenv import load_dotenv
import os

load_dotenv()  # 加载.env文件

db_url = os.getenv('DATABASE_URL')
secret_key = os.getenv('SECRET_KEY')
```

---

## 5. 格式选择

### 对比表

| 格式 | 可读性 | 跨语言 | 结构复杂度 | 性能 | 安全性 |
|------|--------|--------|-----------|------|--------|
| JSON | ⭐⭐⭐⭐ | ✅ | 中等 | 中 | ✅ |
| CSV | ⭐⭐⭐ | ✅ | 简单 | 快 | ✅ |
| pickle | ⭐ | ❌ | 高 | 快 | ⚠️ |
| INI | ⭐⭐⭐⭐ | ✅ | 简单 | 快 | ✅ |

### 使用场景

#### 选择JSON
- ✅ API数据交换
- ✅ 配置文件（复杂配置）
- ✅ 需要跨语言支持
- ✅ 数据结构有嵌套

#### 选择CSV
- ✅ 表格数据导入导出
- ✅ Excel兼容需求
- ✅ 数据分析（pandas）
- ✅ 大量结构化记录

#### 选择pickle
- ✅ Python对象持久化
- ✅ 缓存计算结果
- ✅ 程序间数据传递
- ❌ 不要用于网络传输
- ❌ 不要用于长期存储

#### 选择INI
- ✅ 简单配置文件
- ✅ 用户可编辑配置
- ✅ 分段配置

---

## 6. 最佳实践

### 6.1 错误处理

```python
import json

try:
    with open("config.json", "r") as f:
        config = json.load(f)
except FileNotFoundError:
    config = {}  # 使用默认配置
except json.JSONDecodeError as e:
    print(f"JSON格式错误：{e}")
```

### 6.2 数据验证

```python
import json
from jsonschema import validate, ValidationError

# 定义JSON Schema
schema = {
    "type": "object",
    "properties": {
        "name": {"type": "string"},
        "age": {"type": "integer", "minimum": 0}
    },
    "required": ["name", "age"]
}

# 验证数据
try:
    validate(instance=data, schema=schema)
except ValidationError as e:
    print(f"数据验证失败：{e}")
```

### 6.3 大文件处理

```python
import json

# 逐行读取大JSON文件（JSON Lines格式）
with open("large_data.jsonl", "r") as f:
    for line in f:
        record = json.loads(line)
        process(record)

# CSV逐行处理
import csv
with open("large.csv", "r") as f:
    reader = csv.DictReader(f)
    for row in reader:
        process(row)  # 逐行处理，不占用大量内存
```

### 6.4 性能优化

```python
# JSON：使用ujson（更快）
import ujson as json

# CSV：使用pandas（大批量）
import pandas as pd
df = pd.read_csv("large.csv", chunksize=10000)
for chunk in df:
    process(chunk)

# pickle：使用protocol参数
pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
```

---

## 7. 与Java的对比

| 需求 | Python | Java |
|------|--------|------|
| JSON | `json` 模块 | Jackson / Gson |
| CSV | `csv` 模块 | OpenCSV / Apache Commons CSV |
| 对象序列化 | `pickle` | Java Serializable |
| 配置文件 | `configparser` | Properties / YAML |

---

## 8. 实战示例

### 数据导入导出系统

```python
class DataManager:
    """通用数据管理器"""

    @staticmethod
    def save_json(data, filename):
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    @staticmethod
    def load_json(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return json.load(f)

    @staticmethod
    def export_csv(data, filename, fieldnames):
        with open(filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(data)

    @staticmethod
    def import_csv(filename):
        with open(filename, "r", encoding="utf-8") as f:
            return list(csv.DictReader(f))
```

---

## 在本仓库中的应用

- **所有服务**：Pydantic 模型自动序列化为 JSON 响应
- **配置管理**：各服务 `config.py` 中的环境变量和配置文件读取
- **销售统计项目**：CSV 数据导入导出
- **日志分析项目**：JSON 格式日志解析和报表生成
- **综合练习**：参见 `15_进阶专题.md` 中的"审计日志分析与报表生成"练习

## 相关资源

- [Python官方文档 - json](https://docs.python.org/zh-cn/3/library/json.html)
- [Python官方文档 - csv](https://docs.python.org/zh-cn/3/library/csv.html)
- [Python官方文档 - pickle](https://docs.python.org/zh-cn/3/library/pickle.html)
- [JSON Schema](https://json-schema.org/)
