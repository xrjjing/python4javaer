# 多线程与多进程

> 本专题的目标不是让你一口气精通并发编程，而是站在「实用 + 对比」的角度，帮你搞清楚：什么时候该用多线程、什么时候用多进程，以及它们和前面学过的 `asyncio` 有什么区别。

配套示例代码：

- `01.Python语言基础/15_进阶专题/06_多线程与多进程/demo_concurrency.py`
- 建议后续补充：`practice_concurrency.py` 作为练习题文件

---

## 1. 概念扫盲：并发 vs 并行、CPU 密集 vs IO 密集

在动手写代码之前，先用最简洁的方式把几个容易混的概念区分开：

- **并发（Concurrency）**：看起来「同时」在做多件事，实际上可能是一个 CPU 在不同任务之间来回切换（时间片）。  
- **并行（Parallelism）**：真正意义上的「同时」，例如多核 CPU 上多个进程/线程各占一个核一起跑。
- **CPU 密集型任务**：主要消耗 CPU 计算时间，比如大规模数字运算、加密、图像处理、复杂算法等。
- **IO 密集型任务**：主要时间花在等待 IO 上，比如网络请求、磁盘读写、数据库访问等。

在 CPython 中，由于 GIL（全局解释器锁）的存在：

- 多线程更适合 **IO 密集型任务**（比如并发请求多个 HTTP 接口）；
- 多进程更适合 **CPU 密集型任务**（比如并行计算大量数据）。

`asyncio` 则适合大量 IO 密集且对高并发有要求的场景（例如成百上千个并发网络请求），你在「异步编程入门」专题中已经见过。

---

## 2. 用 ThreadPoolExecutor 并发请求多个 HTTP 接口（IO 密集）

最常见、最实用的多线程场景：**同时请求多个外部 HTTP 接口**。  
例如：调用多个微服务、批量查询第三方平台接口等。

在 `demo_concurrency.py` 中，你会看到类似这样的示例：

```python
from concurrent.futures import ThreadPoolExecutor

def fetch_status(url: str, timeout: float = 5.0) -> tuple[str, int | None]:
    \"\"\"请求 URL 并返回 (url, 状态码)。\"\"\"
    ...

def fetch_all_status(urls: list[str], max_workers: int = 5) -> list[tuple[str, int | None]]:
    \"\"\"使用线程池并发请求一组 URL。\"\"\"
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(fetch_status, url) for url in urls]
        return [f.result() for f in futures]
```

建议你对比以下三种写法的性能和代码可读性：

1. 单线程 for 循环逐个请求；
2. `ThreadPoolExecutor` 实现粗粒度并发；
3. 使用 `asyncio`（参考「异步编程入门」示例）实现更高并发。

一般经验：

- 少量并发（几十个请求以内）：`ThreadPoolExecutor` 足够简单好用；
- 大量并发（上百甚至上千）：考虑 `asyncio` + `aiohttp` 之类的方案。

---

## 3. 用 ProcessPoolExecutor 处理 CPU 密集任务（计算密集）

如果你要做的是「大量计算」，例如：

- 为一大批数据计算复杂指标；
- 在脚本中做一些离线分析（如统计、加密等）；

此时多线程由于 GIL 的限制帮助有限，可以考虑 `multiprocessing` 或 `ProcessPoolExecutor`。

示例（见 `demo_concurrency.py`）：

```python
from concurrent.futures import ProcessPoolExecutor

def count_primes(n: int) -> int:
    \"\"\"粗略计算 [2, n) 范围内的素数个数（示例用，不追求高效算法）。\"\"\"
    ...

def count_primes_in_ranges(ranges: list[tuple[int, int]], max_workers: int = 4) -> list[int]:
    \"\"\"使用进程池并行计算多个区间内的素数个数。\"\"\"
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(count_primes, end) for _, end in ranges]
        return [f.result() for f in futures]
```

注意事项：

- **Windows 下必须放在 `if __name__ == "__main__":` 保护下**，否则可能出现无限递归创建子进程的问题；  
- 子进程之间不共享内存，适合「输入参数比较小、计算过程独立、结果相对简短」的场景。

---

## 4. 与 asyncio 的简单对比：该用谁？

在本仓库中你已经学过：

- `15_进阶专题/07_异步编程入门/demo_async_programming.py`

可以简单记住下面这张「脑图」：

- IO 密集型：
  - 少量并发：`ThreadPoolExecutor`（简单）；  
  - 大量并发：`asyncio`（需要更多心智负担，但更高效）。
- CPU 密集型：
  - 使用 `ProcessPoolExecutor` 或 `multiprocessing`。

在 Web 项目中（例如 FastAPI）：

- 异步端点函数内部可以使用 `asyncio` 做 IO 并发；  
- CPU 密集型任务尽量放到后台任务队列或单独的进程/服务中处理。

你可以尝试在阅读 `03.项目实战/07_监控数据处理_指标聚合与告警` 时思考：  
如果指标计算变得很重，是否有必要用多进程加速，或者拆成离线任务。

---

## 5. 在脚本/服务中的常见使用模式

综合来看，线程/进程在脚本和服务中的使用模式可以概括为：

1. **简易并发脚本**  
   - 用 ThreadPool 批量调用 API、下载文件、处理日志文件等；
2. **离线计算加速**  
   - 用 ProcessPool 在多核上跑 CPU 密集分析任务；
3. **与现有代码集成**  
   - 将「耗时任务」封装成函数，再用线程/进程池调度；
   - 保持主线程逻辑简单，易于测试和维护。

在 `demo_concurrency.py` 中，代码会尽量采用「小函数 + 池」的形式，方便你在自己的脚本里直接借鉴这种结构。

---

## 6. 建议练习（可以在 practice_concurrency.py 中实现）

如果你想进一步巩固本专题的内容，可以尝试完成如下小练习：

1. **并发下载多个网页并统计标题长度**  
   - 给定多个 URL，使用 `ThreadPoolExecutor` 并发下载；  
   - 解析 `<title>` 文本并统计长度，返回列表。
2. **用进程池加速简单统计任务**  
   - 编写一个函数，统计给定整数 n 以内所有数字的位数和（例如 123 → 1+2+3）；  
   - 使用 `ProcessPoolExecutor` 对多个 n 并行计算总和，并验证与单线程结果一致。
3. **对比 asyncio 与线程池的行为**  
   - 任选一个 IO 密集任务（例如请求 `https://httpbin.org/delay/1` 多次）；  
   - 分别用 `ThreadPoolExecutor` 和 `asyncio` 实现，并比较代码复杂度与运行时间。

完成这些练习后，再回头看「异步编程入门」和 `03.项目实战` 中的项目，你会对不同并发模型的优缺点和适用场景有更加直观的理解。

---

## 在本仓库中的应用

- **integration_gateway_service**：网关服务使用 `asyncio` 而非线程池处理并发请求，适合高 IO 场景
- **批量数据处理脚本**：如需批量调用 API 或处理大量文件，可使用 `ThreadPoolExecutor`
- **CPU 密集型离线任务**：如日志统计、数据聚合等，可使用 `ProcessPoolExecutor` 加速
- **FastAPI 异步路由**：各服务的 `async def` 端点利用事件循环处理并发，与线程池形成对比

**适用场景对比**：

| 场景 | 推荐方案 | 本仓库示例 |
|------|----------|-----------|
| 并发 HTTP 请求（少量） | `ThreadPoolExecutor` | 批量调用后端 API |
| 并发 HTTP 请求（大量） | `asyncio` + `httpx` | integration_gateway_service |
| CPU 密集计算 | `ProcessPoolExecutor` | 日志聚合统计 |
| Web 服务端点 | `async def` | FastAPI 路由 |

**Java 对比**：
- Python `ThreadPoolExecutor` ≈ Java `ExecutorService.newFixedThreadPool()`
- Python `ProcessPoolExecutor` ≈ Java `ForkJoinPool`
- Python GIL 限制 ≈ Java 无此限制（JVM 原生多线程）

## 相关资源

- [Python官方文档 - concurrent.futures](https://docs.python.org/zh-cn/3/library/concurrent.futures.html)
- [Python官方文档 - multiprocessing](https://docs.python.org/zh-cn/3/library/multiprocessing.html)
- [Real Python - Python Concurrency](https://realpython.com/python-concurrency/)
