# 05_简单爬虫_新闻标题抓取

> 目标：用最基础的网络请求 + HTML 解析，编写一个简单的网页爬虫，用来抓取页面上的标题列表。练习 `requests`、`BeautifulSoup`、字符串处理等，在真实环境中要严格遵守网站协议与法律法规。

## 1. 项目背景与注意事项

现实工作中，爬虫常见用途包括：

- 自动收集公开网页上的数据（如新闻标题、行情信息、技术文章目录等）；
- 为内部分析或监控准备原始数据；
- 辅助测试（例如自动生成测试数据）。

但是：

- 必须遵守目标网站的 `robots.txt`、使用条款和相关法律法规；
- 不要高频访问、不要绕过登陆 / 支付等访问限制；
- 不要抓取敏感隐私数据。

本项目仅用于学习技术方法，请勿用在任何违规场景。

## 2. 目录与文件说明

```text
03.项目实战/
└── 05_简单爬虫_新闻标题抓取/
    ├── 05_项目说明.md
    └── crawler_news_titles.py   # 简单爬虫脚本
```

## 3. 必要第三方库

- `requests`：发送 HTTP 请求；
- `beautifulsoup4`：解析 HTML。

安装示例：

```bash
pip install requests beautifulsoup4
```

## 4. 运行方式

```bash
python 03.项目实战/05_简单爬虫_新闻标题抓取/crawler_news_titles.py \
  "https://example.com"
```

脚本会：

- 请求指定 URL；
- 尝试从页面中提取 `<a>` 标签中的文本，将可能的标题打印出来；
- 将结果写入当前目录的 `titles.txt` 文件。

## 5. 测试说明

- 本项目有一个针对 HTML 解析逻辑的测试文件：`test_crawler_news_titles.py`。  
- 在仓库根目录运行下面命令可以只跑本项目的测试：

  ```bash
  pytest 03.项目实战/05_简单爬虫_新闻标题抓取/test_crawler_news_titles.py
  ```

测试不会真实发起网络请求，而是构造一段简单的 HTML 字符串，检查：

- `extract_titles(html)` 是否能从 `<a>` 标签中提取文本；
- 是否会自动过滤掉太短、不像标题的文本。

你可以在此基础上扩展更多「专门针对某个网站」的解析测试，例如验证某个站点的标题 CSS 选择器是否写对。

## 5. 扩展练习

- 针对你经常访问的某个技术网站编写「专用解析函数」，只抓取真正的文章标题；
- 给爬虫增加简单的「防爬礼貌」功能，例如随机 `User-Agent`、请求间隔；
- 将结果保存为 CSV，字段包括：标题、链接、抓取时间；
- 思考如何在公司内部规范使用爬虫，以避免违规风险。
