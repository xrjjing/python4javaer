# 新闻爬虫进阶与最佳实践（2025 版）

> 结合最新社区经验与论文结论，帮助你在合法、稳定、可扩展的前提下编写爬虫。

## 1. 合法与合规
- **尊重 robots.txt 与站点 ToS**：先检查 `robots.txt` 再抓取，若被禁止则改用公开 API 或放弃。citeturn0search0turn0search7
- **标识 UA**：自定义 `User-Agent`，可带联系页。citeturn0search2
- **避免 DoS**：加延时/限速，初次抓取可 1 请求/10–15s，按响应情况再调。citeturn0search5
- **数据用途**：不要抓取个人隐私/受版权保护的内容；谨慎处理登录态与反爬限制。citeturn0search2

## 2. 性能与稳定
- **并发请求**：静态页面用 `httpx.AsyncClient` + `asyncio.gather`，比 requests 同步快 6–10 倍。citeturn0search10
- **速率控制**：实现自适应 RateLimiter（见 `crawler_news_httpx.py`），按错误率动态减速。citeturn0search9
- **缓存与去重**：重复访问同一列表页应本地缓存，节省带宽/被封风险。citeturn0search2
- **异常重试**：对 429/5xx 采用退避重试；对 403/验证码应直接放弃或切换代理。

## 3. 解析策略
- **优先结构化选择器**：用 CSS 选择器而非纯文本搜索，减少误匹配。
- **容错**：部分站点 HTML 不规范，可 `soup.prettify()` 诊断；必要时 fallback 到 `lxml`。citeturn0search9
- **动态页面**：若必须执行 JS，考虑 Playwright/selenium；但成本高，应先判断页面是否真需要 JS。citeturn0search3

## 4. 代理与封禁对策（仅在合法场景）
- 使用付费稳定代理而非免费列表；频率控制永远是首要，代理只作兜底。
- 随机 UA 与请求间隔的抖动可降低被判定为机器人风险。citeturn0search8

## 5. 本仓库的实践
- **离线优先**：默认解析 `sample_news.html`；网络受限也能学习。
- **同步版**：`crawler_news_bs4.py` —— 适合教学。
- **异步版**：`crawler_news_httpx.py` —— 演示 httpx + RateLimiter + robots 检查。
- **单测**：`test_crawler_news_bs4.py` 使用本地 HTML，确保解析逻辑稳定。

## 6. 建议的演练步骤
1. 运行同步脚本：`python crawler_news_bs4.py`（离线）。
2. 查看高级教程代码：`crawler_news_httpx.py`，学习 robots 检查与速率限制。
3. 将目标站点 URL 替换为自己可合法抓取的页面，逐步调低延迟。
4. 添加缓存与日志，观察被封/错误率变化，调整限速策略。
