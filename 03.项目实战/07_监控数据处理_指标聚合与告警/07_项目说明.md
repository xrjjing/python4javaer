# 07_监控数据处理_指标聚合与告警

> 目标：模拟处理监控系统导出的原始指标数据，完成统计聚合与简单告警。练习文件读取、字典统计、简单规则引擎，为以后接入真实监控系统（如 Prometheus、日志平台）打基础。

## 1. 项目背景

在后端开发 / 运维工作中，常见的监控数据包括：

- 接口请求耗时；
- QPS / 请求数量；
- 错误率；
- 系统资源使用（CPU、内存等）。

这些数据通常会被写入：

- 日志文件；
- 时序数据库；
- 监控平台的导出文件。

本项目通过一个简化的 CSV 文件来模拟监控数据，练习如何：

- 读取并解析原始数据；
- 按指标维度统计平均值 / 最大值；
- 根据阈值规则生成告警。

## 2. 目录与文件说明

```text
03.项目实战/
└── 07_监控数据处理_指标聚合与告警/
    ├── 07_项目说明.md
    ├── metrics_sample.csv       # 示例监控数据（需要你自己准备）
    └── process_metrics.py       # 指标处理与告警脚本
```

- `metrics_sample.csv` 建议包含列：
  - `timestamp`：时间戳，如 `2025-01-01T12:00:00`
  - `metric`：指标名称，如 `http_requests_duration_ms`
  - `value`：数值，如 `123.4`

示例：

```text
timestamp,metric,value
2025-01-01T12:00:00,http_requests_duration_ms,120
2025-01-01T12:00:10,http_requests_duration_ms,350
2025-01-01T12:00:20,http_requests_duration_ms,90
```

## 3. 运行方式

```bash
python 03.项目实战/07_监控数据处理_指标聚合与告警/process_metrics.py
```

脚本会：

- 读取 `metrics_sample.csv`；
- 按指标名称统计平均值、最大值；
- 对部分指标执行阈值检查（例如某指标最大值 > 阈值则触发告警，并打印告警信息）。

## 5. 测试说明

- 本项目有一个基础测试文件：`test_process_metrics.py`。  
- 在仓库根目录运行下面命令可以只跑本项目的测试：

  ```bash
  pytest 03.项目实战/07_监控数据处理_指标聚合与告警/test_process_metrics.py
  ```

测试通过构造一组内存中的指标数据行，重点验证：

- `aggregate_metrics` 是否会按 `metric` 字段正确聚合；
- `MetricStat` 中 `count`、`average`、`max_value` 的计算是否符合预期。

日后如果你扩展了更多复杂告警规则，也可以在这个测试文件里新增针对规则的单元测试。

## 4. 扩展练习

- 将告警结果写入 `alerts.log` 文件，记录时间、指标名、阈值与实际值；
- 为脚本增加命令行参数，可以指定数据文件路径和阈值配置文件路径；
- 将处理结果导出为 JSON，方便其他系统（比如 Web 面板）使用；
- 结合 FastAPI，将统计结果通过简单 API 暴露出去，做一个最小「监控查询接口」。
