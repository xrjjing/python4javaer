# 07 异步与背景任务（FastAPI vs Spring 视角）

> 面向对象：从 Java / Spring 迁移到 Python / FastAPI 的同学。
> 目标：掌握 FastAPI 异步编程模式、BackgroundTasks、长任务状态跟踪、重试策略，理解与 Spring @Async / CompletableFuture 的映射。

---

## 0. 快速对照：Spring vs FastAPI

| 维度 | Spring | FastAPI |
| --- | --- | --- |
| 异步执行 | `@Async` + `@EnableAsync` | `async def` + `await` |
| 异步返回 | `CompletableFuture<T>` | 原生协程（coroutine） |
| 后台任务 | `TaskExecutor.execute()` | `BackgroundTasks.add_task()` |
| 定时任务 | `@Scheduled` / Quartz | APScheduler / Celery Beat |
| 任务队列 | RabbitMQ / Kafka + 消费者 | Celery + Redis/RabbitMQ |
| 线程池 | `ThreadPoolTaskExecutor` | `asyncio.to_thread()` + 自定义 `ThreadPoolExecutor` |

**记忆句**：FastAPI 基于单线程事件循环 + 协程，避免阻塞是关键；Java 多线程模型更宽松但需管理线程池。

---

## 1. 异步基础回顾

### 1.1 同步 vs 异步端点

```python
from fastapi import FastAPI
import time
import asyncio

app = FastAPI()

# 同步端点：会阻塞工作线程
@app.get("/sync")
def sync_endpoint():
    time.sleep(1)  # 阻塞 1 秒
    return {"type": "sync"}

# 异步端点：不阻塞事件循环
@app.get("/async")
async def async_endpoint():
    await asyncio.sleep(1)  # 非阻塞等待
    return {"type": "async"}
```

### 1.2 何时用 async

| 场景 | 推荐 | 原因 |
| --- | --- | --- |
| 异步 I/O（httpx、aiofiles） | `async def` | 充分利用非阻塞 |
| 同步 I/O（requests、open） | `def` | 避免阻塞事件循环 |
| CPU 密集计算 | `def` + 线程池 | 防止卡死其他请求 |

### 1.3 阻塞调用的正确处理

```python
import asyncio
from functools import partial

def blocking_io():
    """模拟同步阻塞操作（如调用某些只有同步接口的 SDK）"""
    import time
    time.sleep(2)
    return "done"

@app.get("/wrap-blocking")
async def wrap_blocking():
    # 方式 1：asyncio.to_thread (Python 3.9+)
    result = await asyncio.to_thread(blocking_io)
    return {"result": result}

    # 方式 2：run_in_executor
    # loop = asyncio.get_event_loop()
    # result = await loop.run_in_executor(None, blocking_io)
```

---

## 2. BackgroundTasks 使用

### 2.1 基本用法

```python
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel, EmailStr

app = FastAPI()

class SignupRequest(BaseModel):
    email: EmailStr
    name: str

def send_welcome_email(email: str, name: str):
    """后台发送欢迎邮件（fire-and-forget）"""
    import time
    time.sleep(2)  # 模拟耗时操作
    print(f"已发送邮件到 {email}, 欢迎 {name}!")

@app.post("/signup")
async def signup(payload: SignupRequest, background_tasks: BackgroundTasks):
    # 1. 同步业务逻辑（如写入数据库）
    user_id = "user_123"

    # 2. 将耗时操作放入后台执行
    background_tasks.add_task(send_welcome_email, payload.email, payload.name)

    # 3. 立即返回响应
    return {"user_id": user_id, "message": "注册成功，欢迎邮件已排队"}
```

### 2.2 异步后台任务

```python
import httpx

async def send_email_async(to: str, subject: str, body: str):
    """异步发送邮件"""
    async with httpx.AsyncClient(timeout=10) as client:
        await client.post(
            "https://api.mailgun.net/v3/example/messages",
            auth=("api", "MAILGUN_API_KEY"),
            data={"from": "noreply@example.com", "to": to, "subject": subject, "text": body},
        )

@app.post("/signup-async")
async def signup_async(payload: SignupRequest, background_tasks: BackgroundTasks):
    # 支持异步函数
    background_tasks.add_task(send_email_async, payload.email, "欢迎", f"Hi {payload.name}!")
    return {"message": "注册成功"}
```

### 2.3 Java 对比

```java
// Spring @Async
@Service
public class EmailService {
    @Async
    public CompletableFuture<Void> sendWelcomeEmail(String email, String name) {
        // 发送邮件逻辑
        return CompletableFuture.completedFuture(null);
    }
}

// 调用方
@PostMapping("/signup")
public ResponseEntity<?> signup(@RequestBody SignupRequest req) {
    emailService.sendWelcomeEmail(req.email, req.name);  // 异步执行
    return ResponseEntity.ok(Map.of("message", "注册成功"));
}
```

---

## 3. 长任务状态跟踪

### 3.1 设计模式

```
POST /tasks      → 创建任务，返回 task_id
GET  /tasks/{id} → 查询任务状态（running/succeeded/failed）
DELETE /tasks/{id} → 取消任务（可选）
```

### 3.2 内存版实现（演示用）

```python
import asyncio
from uuid import uuid4
from dataclasses import dataclass
from fastapi import FastAPI, HTTPException

app = FastAPI()

@dataclass
class TaskInfo:
    status: str  # running | succeeded | failed
    result: dict | None = None
    error: str | None = None

TASKS: dict[str, TaskInfo] = {}

async def heavy_job(n: int, task_id: str):
    """模拟耗时计算任务"""
    try:
        await asyncio.sleep(5)  # 模拟耗时
        TASKS[task_id].result = {"sum": sum(range(n))}
        TASKS[task_id].status = "succeeded"
    except asyncio.CancelledError:
        TASKS[task_id].status = "cancelled"
    except Exception as exc:
        TASKS[task_id].status = "failed"
        TASKS[task_id].error = str(exc)

@app.post("/tasks")
async def create_task(n: int = 100):
    task_id = str(uuid4())
    TASKS[task_id] = TaskInfo(status="running")
    asyncio.create_task(heavy_job(n, task_id))
    return {"task_id": task_id}

@app.get("/tasks/{task_id}")
async def get_task(task_id: str):
    info = TASKS.get(task_id)
    if not info:
        raise HTTPException(status_code=404, detail="Task not found")
    return {"status": info.status, "result": info.result, "error": info.error}
```

### 3.3 生产建议

| 演示版 | 生产版 |
| --- | --- |
| 内存存储 | Redis / 数据库持久化 |
| 无 TTL | 设置过期时间，定期清理 |
| 单实例 | 分布式任务队列（Celery） |
| 无取消 | 支持优雅取消 |

---

## 4. 重试策略

### 4.1 简易重试装饰器

```python
import asyncio
import time
from collections.abc import Callable
from functools import wraps

def retry(
    max_attempts: int = 3,
    base_delay: float = 0.5,
    backoff: float = 2.0,
    retry_exceptions: tuple = (Exception,),
):
    """
    通用重试装饰器，支持同步/异步函数
    - max_attempts: 最大尝试次数
    - base_delay: 初始延迟（秒）
    - backoff: 退避倍数
    - retry_exceptions: 触发重试的异常类型
    """
    def decorator(func: Callable):
        if asyncio.iscoroutinefunction(func):
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                delay = base_delay
                for attempt in range(1, max_attempts + 1):
                    try:
                        return await func(*args, **kwargs)
                    except retry_exceptions as e:
                        if attempt == max_attempts:
                            raise
                        await asyncio.sleep(delay)
                        delay *= backoff
            return async_wrapper
        else:
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                delay = base_delay
                for attempt in range(1, max_attempts + 1):
                    try:
                        return func(*args, **kwargs)
                    except retry_exceptions as e:
                        if attempt == max_attempts:
                            raise
                        time.sleep(delay)
                        delay *= backoff
            return sync_wrapper
    return decorator
```

### 4.2 使用示例

```python
import httpx

@retry(max_attempts=3, base_delay=1.0, retry_exceptions=(httpx.TimeoutException,))
async def fetch_external_api(url: str) -> dict:
    async with httpx.AsyncClient(timeout=5) as client:
        resp = await client.get(url)
        resp.raise_for_status()
        return resp.json()
```

### 4.3 幂等性要求

```python
# ❌ 非幂等操作直接重试有副作用
async def create_order(item_id: str):
    # 重试可能创建多个订单！
    ...

# ✅ 使用幂等键确保安全重试
async def create_order_idempotent(item_id: str, idempotency_key: str):
    # 先检查该 key 是否已处理
    if await redis.exists(f"order:{idempotency_key}"):
        return await get_existing_order(idempotency_key)
    # 创建订单并记录 key
    order = await do_create_order(item_id)
    await redis.setex(f"order:{idempotency_key}", 3600, order.id)
    return order
```

---

## 5. 并发控制

### 5.1 Semaphore 限制并发

```python
import asyncio
import httpx
from contextlib import asynccontextmanager

# 全局客户端（复用连接池）和信号量
http_client: httpx.AsyncClient | None = None
semaphore = asyncio.Semaphore(10)

@asynccontextmanager
async def lifespan(app):
    global http_client
    http_client = httpx.AsyncClient(timeout=10)
    yield
    await http_client.aclose()

app = FastAPI(lifespan=lifespan)

async def fetch_with_limit(url: str) -> dict:
    async with semaphore:  # 限制并发数
        try:
            resp = await http_client.get(url)
            resp.raise_for_status()
            return {"url": url, "data": resp.json()}
        except httpx.TimeoutException:
            return {"url": url, "error": "timeout"}
        except httpx.HTTPStatusError as e:
            return {"url": url, "error": f"HTTP {e.response.status_code}"}

@app.post("/batch")
async def batch_fetch(urls: list[str]):
    tasks = [fetch_with_limit(url) for url in urls]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return {"results": results}
```

### 5.2 超时控制

```python
import asyncio

async def with_timeout():
    try:
        # Python 3.11+ 推荐
        async with asyncio.timeout(5):
            result = await long_running_operation()
            return result
    except asyncio.TimeoutError:
        return {"error": "操作超时"}

# 或使用 wait_for
async def with_wait_for():
    try:
        result = await asyncio.wait_for(long_running_operation(), timeout=5)
        return result
    except asyncio.TimeoutError:
        return {"error": "操作超时"}
```

---

## 6. Celery 集成触点

### 6.1 基本结构

```python
# celery_app.py
from celery import Celery

celery = Celery(
    "tasks",
    broker="redis://localhost:6379/0",
    backend="redis://localhost:6379/1",
)

celery.conf.update(
    task_serializer="json",
    result_serializer="json",
    accept_content=["json"],
    timezone="Asia/Shanghai",
    task_acks_late=True,  # 任务完成后才确认
    task_reject_on_worker_lost=True,
)

@celery.task(bind=True, max_retries=3)
def send_email_task(self, to: str, subject: str, body: str):
    try:
        # 发送邮件逻辑
        pass
    except Exception as exc:
        raise self.retry(exc=exc, countdown=60)  # 60 秒后重试
```

### 6.2 FastAPI 集成

```python
from fastapi import FastAPI
from celery_app import send_email_task

app = FastAPI()

@app.post("/signup-celery")
async def signup_celery(email: str, name: str):
    # 异步提交任务到 Celery
    task = send_email_task.delay(email, "欢迎", f"Hi {name}!")
    return {"task_id": task.id, "message": "任务已提交"}

@app.get("/task-status/{task_id}")
async def get_task_status(task_id: str):
    from celery.result import AsyncResult
    result = AsyncResult(task_id)
    return {
        "task_id": task_id,
        "status": result.status,
        "result": result.result if result.ready() else None,
    }
```

### 6.3 Java 对比

| FastAPI + Celery | Spring + RabbitMQ |
| --- | --- |
| `@celery.task` | `@RabbitListener` |
| `task.delay()` | `rabbitTemplate.send()` |
| Redis backend | 可选 Redis/DB |
| Flower 监控 | Spring Admin / Prometheus |

---

## 7. 可观测性

### 7.1 Trace ID 传递到后台任务

```python
import logging
import contextvars
from uuid import uuid4

logger = logging.getLogger(__name__)
trace_id_ctx: contextvars.ContextVar[str] = contextvars.ContextVar("trace_id", default="-")

def background_task_with_trace(trace_id: str, payload: dict):
    """后台任务需要显式传入 trace_id"""
    # 设置上下文
    token = trace_id_ctx.set(trace_id)
    try:
        # 执行任务，日志会包含 trace_id
        logger.info(f"[{trace_id}] Processing: {payload}")
    finally:
        trace_id_ctx.reset(token)

@app.post("/process")
async def process(payload: dict, background_tasks: BackgroundTasks):
    trace_id = trace_id_ctx.get()
    # 显式传递 trace_id 到后台任务
    background_tasks.add_task(background_task_with_trace, trace_id, payload)
    return {"message": "已排队"}
```

### 7.2 Java 对比

```java
// Spring：MDC 传递
@Async
public void asyncTask(String traceId, Map<String, Object> payload) {
    MDC.put("traceId", traceId);
    try {
        // 处理逻辑
    } finally {
        MDC.remove("traceId");
    }
}
```

---

## 8. Java vs Python 小贴士

| 场景 | Spring | FastAPI |
| --- | --- | --- |
| 异步执行 | `@Async` + 代理 | `async def` 原生支持 |
| 返回类型 | `CompletableFuture<T>` | 协程 / `asyncio.Task` |
| 线程池 | `ThreadPoolTaskExecutor` | `asyncio.to_thread()` |
| 任务取消 | `Future.cancel(true)` | `task.cancel()` + `CancelledError` |
| 链式调用 | `thenApply/thenCompose` | `await` + 普通 Python 代码 |
| 异常处理 | `exceptionally/handle` | `try/except` |
| 上下文传递 | `SecurityContext` 手动复制 | `contextvars` 或显式参数 |

---

## 9. ⚠️ 常见陷阱

1. **在 async 中调用阻塞操作**
   - 问题：`time.sleep()`、同步 HTTP 库阻塞事件循环
   - 解决：使用 `asyncio.to_thread()` 或异步库

2. **忘记关闭资源**
   - 问题：`httpx.AsyncClient()` 未关闭导致连接泄漏
   - 解决：使用 `async with` 上下文管理器

3. **无限并发**
   - 问题：大量 `create_task()` 触发外部 API 限速
   - 解决：使用 `Semaphore` 限制并发数

4. **后台任务异常静默**
   - 问题：后台任务抛异常但无日志
   - 解决：在任务内捕获异常并记录

5. **幂等性缺失**
   - 问题：重试导致重复操作（多发邮件、重复扣款）
   - 解决：使用幂等键，先查后写

6. **上下文丢失**
   - 问题：后台任务无法获取请求上下文
   - 解决：显式传递 trace_id、user_id 等参数

---

## 10. 完整示例

```python
# main.py
import asyncio
import logging
import time
from uuid import uuid4
from dataclasses import dataclass, field
from contextlib import asynccontextmanager
from functools import wraps
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === 任务存储 ===
@dataclass
class TaskInfo:
    status: str
    result: dict | None = None
    error: str | None = None
    task: asyncio.Task | None = field(default=None, repr=False)

TASKS: dict[str, TaskInfo] = {}

# === 重试装饰器（仅异步版，详见 4.1 节通用版本） ===
def async_retry(max_attempts=3, base_delay=0.5, backoff=2.0):
    """异步重试装饰器，仅用于 async 函数"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            delay = base_delay
            for attempt in range(1, max_attempts + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception:
                    if attempt == max_attempts:
                        raise
                    await asyncio.sleep(delay)
                    delay *= backoff
        return wrapper
    return decorator

# === 后台任务 ===
async def heavy_computation(n: int, task_id: str):
    """长时间计算任务"""
    try:
        await asyncio.sleep(3)  # 模拟耗时
        TASKS[task_id].result = {"sum": sum(range(n)), "n": n}
        TASKS[task_id].status = "succeeded"
        logger.info(f"Task {task_id} completed successfully")
    except asyncio.CancelledError:
        TASKS[task_id].status = "cancelled"
        logger.info(f"Task {task_id} was cancelled")
    except Exception as exc:
        TASKS[task_id].status = "failed"
        TASKS[task_id].error = str(exc)
        logger.error(f"Task {task_id} failed: {exc}")

async def send_notification_async(email: str, message: str):
    """异步发送通知（推荐）"""
    await asyncio.sleep(0.5)  # 模拟异步 I/O
    logger.info(f"通知已发送到 {email}: {message}")

# === 生命周期管理 ===
@asynccontextmanager
async def lifespan(app):
    yield
    # 关闭时取消所有运行中的任务
    for task_id, info in TASKS.items():
        if info.task and not info.task.done():
            info.task.cancel()
            logger.info(f"Cancelling task {task_id}")

app = FastAPI(title="Async Tasks Demo", lifespan=lifespan)

# === 路由 ===
class ComputeRequest(BaseModel):
    n: int = 100
    notify_email: str | None = None

@app.post("/compute")
async def start_compute(req: ComputeRequest, background_tasks: BackgroundTasks):
    task_id = str(uuid4())
    # 创建任务并保存句柄，便于后续取消
    task = asyncio.create_task(heavy_computation(req.n, task_id))
    TASKS[task_id] = TaskInfo(status="running", task=task)

    # 可选：启动后发送通知
    if req.notify_email:
        background_tasks.add_task(
            send_notification_async, req.notify_email, f"任务 {task_id} 已开始"
        )

    return {"task_id": task_id}

@app.get("/compute/{task_id}")
async def get_compute_status(task_id: str):
    info = TASKS.get(task_id)
    if not info:
        raise HTTPException(status_code=404, detail="Task not found")
    return {"task_id": task_id, "status": info.status, "result": info.result, "error": info.error}

@app.delete("/compute/{task_id}")
async def cancel_compute(task_id: str):
    info = TASKS.get(task_id)
    if not info:
        raise HTTPException(status_code=404, detail="Task not found")
    if info.task and not info.task.done():
        info.task.cancel()
        return {"message": f"Task {task_id} cancellation requested"}
    return {"message": f"Task {task_id} already finished"}

@app.get("/health")
async def health():
    return {"status": "ok"}
```

---

## 11. 练习

### 练习 1：BackgroundTasks 邮件发送
实现用户注册后异步发送欢迎邮件：
- 定义 `/signup` 端点接收用户信息
- 使用 BackgroundTasks 发送邮件
- 立即返回注册成功响应

### 练习 2：任务状态跟踪
实现长任务状态查询 API：
- `POST /tasks` 创建任务，返回 task_id
- `GET /tasks/{task_id}` 查询状态
- 支持 running/succeeded/failed 状态

### 练习 3：重试装饰器
实现支持指数退避的重试装饰器：
- 支持配置最大重试次数
- 支持配置初始延迟和退避倍数
- 同时支持同步和异步函数

### 练习 4：并发控制
使用 Semaphore 实现并发限制：
- 批量请求多个 URL
- 限制最大并发数为 5
- 收集所有结果返回

---

## 12. 小结

- `BackgroundTasks` 适合轻量级 fire-and-forget 任务
- 长任务需要状态跟踪和持久化存储
- 在 async 函数中避免阻塞调用，使用 `asyncio.to_thread()`
- 重试需确保操作幂等，使用幂等键
- 并发控制使用 `Semaphore`，超时使用 `asyncio.timeout()`
- 生产环境长任务推荐 Celery + Redis
- 上下文（trace_id、user_id）需显式传递给后台任务
